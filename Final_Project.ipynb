{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e13cb1dc-2b90-451d-9e7f-f3c487d46714",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02d73c0c-8dae-4e4f-a472-c10493016e48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientId</th>\n",
       "      <th>AppointmentID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ScheduledDay</th>\n",
       "      <th>AppointmentDay</th>\n",
       "      <th>Age</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hipertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Alcoholism</th>\n",
       "      <th>Handcap</th>\n",
       "      <th>SMS_received</th>\n",
       "      <th>No-show</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.987250e+13</td>\n",
       "      <td>5642903</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T18:38:08Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>62</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.589978e+14</td>\n",
       "      <td>5642503</td>\n",
       "      <td>M</td>\n",
       "      <td>2016-04-29T16:08:27Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.262962e+12</td>\n",
       "      <td>5642549</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T16:19:04Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>62</td>\n",
       "      <td>MATA DA PRAIA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.679512e+11</td>\n",
       "      <td>5642828</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T17:29:31Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>8</td>\n",
       "      <td>PONTAL DE CAMBURI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.841186e+12</td>\n",
       "      <td>5642494</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T16:07:23Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PatientId  AppointmentID Gender  ... Handcap SMS_received  No-show\n",
       "0  2.987250e+13        5642903      F  ...       0            0       No\n",
       "1  5.589978e+14        5642503      M  ...       0            0       No\n",
       "2  4.262962e+12        5642549      F  ...       0            0       No\n",
       "3  8.679512e+11        5642828      F  ...       0            0       No\n",
       "4  8.841186e+12        5642494      F  ...       0            0       No\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# LOAD FILE FROM WORKSPACE FILES\n",
    "# =========================\n",
    "\n",
    "DATA_PATH = \"/Workspace/Users/sealex@asu.edu/KaggleV2-May-2016.csv\"  \n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c6562fe-69ae-4151-b36a-15481c1e4ceb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial rows: 110527\nColumns: ['PatientId', 'AppointmentID', 'Gender', 'ScheduledDay', 'AppointmentDay', 'Age', 'Neighbourhood', 'Scholarship', 'Hipertension', 'Diabetes', 'Alcoholism', 'Handcap', 'SMS_received', 'No-show']\nUnique raw NoShow values: ['no' 'yes']\nRows after target clean: 110527\nNoShow value counts:\nNoShow\n0    88208\n1    22319\nName: count, dtype: int64\nAge NaNs before drop: 0\nRows after age filter: 110526\n\nNa counts before dropping bad dates:\nScheduledDay      0\nAppointmentDay    0\ndtype: int64\nRows after dropping NaN dates: 110526\n\nDaysBetween summary before filter:\ncount    110526.000000\nmean          9.183794\nstd          15.255034\nmin          -7.000000\n25%          -1.000000\n50%           3.000000\n75%          14.000000\nmax         178.000000\nName: DaysBetween, dtype: float64\nRows after DaysBetween >= 0: 71959\n\nFinal row count after cleaning: 71959\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientId</th>\n",
       "      <th>AppointmentID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ScheduledDay</th>\n",
       "      <th>AppointmentDay</th>\n",
       "      <th>Age</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hipertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Alcoholism</th>\n",
       "      <th>Handcap</th>\n",
       "      <th>SMS_received</th>\n",
       "      <th>NoShow</th>\n",
       "      <th>DaysBetween</th>\n",
       "      <th>ApptWeekday</th>\n",
       "      <th>IsWeekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.598513e+13</td>\n",
       "      <td>5626772</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-27 08:36:51+00:00</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>76</td>\n",
       "      <td>REPÚBLICA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.336882e+14</td>\n",
       "      <td>5630279</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-27 15:05:12+00:00</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>GOIABEIRAS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.449833e+12</td>\n",
       "      <td>5630575</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-27 15:39:58+00:00</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>39</td>\n",
       "      <td>GOIABEIRAS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.812456e+13</td>\n",
       "      <td>5629123</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-27 12:48:25+00:00</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>CONQUISTA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.345362e+14</td>\n",
       "      <td>5630213</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-27 14:58:11+00:00</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>30</td>\n",
       "      <td>NOVA PALESTINA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PatientId  AppointmentID Gender  ... DaysBetween ApptWeekday  IsWeekend\n",
       "5   9.598513e+13        5626772      F  ...           1      Friday          0\n",
       "6   7.336882e+14        5630279      F  ...           1      Friday          0\n",
       "7   3.449833e+12        5630575      F  ...           1      Friday          0\n",
       "9   7.812456e+13        5629123      F  ...           1      Friday          0\n",
       "10  7.345362e+14        5630213      F  ...           1      Friday          0\n",
       "\n",
       "[5 rows x 17 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# CLEANING & FEATURE ENGINEERING (SAFE VERSION)\n",
    "# =========================\n",
    "\n",
    "df = df.copy()\n",
    "print(\"Initial rows:\", len(df))\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# 1) Fix target column name\n",
    "df = df.rename(columns={\"No-show\": \"NoShow\"})\n",
    "\n",
    "# 2) Clean and map target robustly\n",
    "df[\"NoShow\"] = df[\"NoShow\"].astype(str).str.strip().str.lower()\n",
    "print(\"Unique raw NoShow values:\", df[\"NoShow\"].unique())\n",
    "\n",
    "# Keep only yes/no rows and map to 1/0\n",
    "df = df[df[\"NoShow\"].isin([\"yes\", \"no\"])]\n",
    "df[\"NoShow\"] = df[\"NoShow\"].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "print(\"Rows after target clean:\", len(df))\n",
    "print(\"NoShow value counts:\")\n",
    "print(df[\"NoShow\"].value_counts())\n",
    "\n",
    "# 3) Make Age numeric then filter\n",
    "df[\"Age\"] = pd.to_numeric(df[\"Age\"], errors=\"coerce\")\n",
    "print(\"Age NaNs before drop:\", df[\"Age\"].isna().sum())\n",
    "\n",
    "df = df.dropna(subset=[\"Age\"])\n",
    "df = df[(df[\"Age\"] >= 0) & (df[\"Age\"] <= 120)]\n",
    "print(\"Rows after age filter:\", len(df))\n",
    "\n",
    "# 4) Parse date columns\n",
    "df[\"ScheduledDay\"] = pd.to_datetime(df[\"ScheduledDay\"], errors=\"coerce\")\n",
    "df[\"AppointmentDay\"] = pd.to_datetime(df[\"AppointmentDay\"], errors=\"coerce\")\n",
    "\n",
    "print(\"\\nNa counts before dropping bad dates:\")\n",
    "print(df[[\"ScheduledDay\", \"AppointmentDay\"]].isna().sum())\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "df = df.dropna(subset=[\"ScheduledDay\", \"AppointmentDay\"])\n",
    "print(\"Rows after dropping NaN dates:\", len(df))\n",
    "\n",
    "# 5) DaysBetween\n",
    "df[\"DaysBetween\"] = (df[\"AppointmentDay\"] - df[\"ScheduledDay\"]).dt.days\n",
    "print(\"\\nDaysBetween summary before filter:\")\n",
    "print(df[\"DaysBetween\"].describe())\n",
    "\n",
    "df = df[df[\"DaysBetween\"] >= 0]\n",
    "print(\"Rows after DaysBetween >= 0:\", len(df))\n",
    "\n",
    "# 6) Weekday + weekend flag\n",
    "df[\"ApptWeekday\"] = df[\"AppointmentDay\"].dt.day_name()\n",
    "df[\"IsWeekend\"] = df[\"AppointmentDay\"].dt.weekday.isin([5, 6]).astype(int)\n",
    "\n",
    "print(\"\\nFinal row count after cleaning:\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82b3d433-8a7b-42b4-be80-3f763134fb53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['Age', 'DaysBetween']\nBinary features: ['Scholarship', 'Hipertension', 'Diabetes', 'Alcoholism', 'Handcap', 'SMS_received', 'IsWeekend']\nCategorical features: ['Gender', 'Neighbourhood', 'ApptWeekday']\nTotal features: 12\nX shape: (71959, 12)\ny distribution:\nNoShow\n0    51437\n1    20522\nName: count, dtype: int64\nTrain shape: (57567, 12)\nTest shape: (14392, 12)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# FEATURE SETUP & TRAIN/TEST SPLIT (CLEAN)\n",
    "# =========================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_col = \"NoShow\"\n",
    "\n",
    "numeric_features = [\"Age\", \"DaysBetween\"]\n",
    "binary_int_cols = [\"Scholarship\", \"Hipertension\", \"Diabetes\",\n",
    "                   \"Alcoholism\", \"Handcap\", \"SMS_received\", \"IsWeekend\"]\n",
    "categorical_features = [\"Gender\", \"Neighbourhood\", \"ApptWeekday\"]\n",
    "\n",
    "# Keep only existing columns (safety)\n",
    "numeric_features = [c for c in numeric_features if c in df.columns]\n",
    "binary_int_cols = [c for c in binary_int_cols if c in df.columns]\n",
    "categorical_features = [c for c in categorical_features if c in df.columns]\n",
    "\n",
    "feature_cols = numeric_features + binary_int_cols + categorical_features\n",
    "\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Binary features:\", binary_int_cols)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"Total features:\", len(feature_cols))\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target_col].astype(int)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "423da8be-c59b-458c-9161-c785dafe48cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5635769872151195\nPrecision: 0.3416727272727273\nRecall   : 0.5723684210526315\nF1       : 0.42790782402768923\nROC AUC  : 0.5898881581789492\n\nClassification report:\n\n              precision    recall  f1-score   support\n\n           0       0.77      0.56      0.65     10288\n           1       0.34      0.57      0.43      4104\n\n    accuracy                           0.56     14392\n   macro avg       0.55      0.57      0.54     14392\nweighted avg       0.65      0.56      0.58     14392\n\nConfusion matrix:\n[[5762 4526]\n [1755 2349]]\n=== RANDOM FOREST RESULTS ===\nAccuracy : 0.6856586992773763\nPrecision: 0.4074074074074074\nRecall   : 0.22514619883040934\nF1       : 0.2900188323917137\nROC AUC  : 0.6018400925660661\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n           0       0.74      0.87      0.80     10288\n           1       0.41      0.23      0.29      4104\n\n    accuracy                           0.69     14392\n   macro avg       0.57      0.55      0.54     14392\nweighted avg       0.64      0.69      0.65     14392\n\nConfusion Matrix:\n[[8944 1344]\n [3180  924]]\n=== GRADIENT BOOSTING RESULTS ===\nAccuracy : 0.7149805447470817\nPrecision: 0.5092592592592593\nRecall   : 0.013401559454191032\nF1       : 0.026115859449192782\nROC AUC  : 0.609096531112536\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n           0       0.72      0.99      0.83     10288\n           1       0.51      0.01      0.03      4104\n\n    accuracy                           0.71     14392\n   macro avg       0.61      0.50      0.43     14392\nweighted avg       0.66      0.71      0.60     14392\n\nConfusion Matrix:\n[[10235    53]\n [ 4049    55]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.563577</td>\n",
       "      <td>0.341673</td>\n",
       "      <td>0.572368</td>\n",
       "      <td>0.427908</td>\n",
       "      <td>0.589888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.685659</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.225146</td>\n",
       "      <td>0.290019</td>\n",
       "      <td>0.601840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.714981</td>\n",
       "      <td>0.509259</td>\n",
       "      <td>0.013402</td>\n",
       "      <td>0.026116</td>\n",
       "      <td>0.609097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score   ROC AUC\n",
       "0  Logistic Regression  0.563577   0.341673  0.572368  0.427908  0.589888\n",
       "1        Random Forest  0.685659   0.407407  0.225146  0.290019  0.601840\n",
       "2    Gradient Boosting  0.714981   0.509259  0.013402  0.026116  0.609097"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# PIPELINE, TRAINING, EVALUATION\n",
    "# =========================\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# numeric (Age, DaysBetween + all 0/1 flags)\n",
    "all_numeric = numeric_features + binary_int_cols\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, all_numeric),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", log_reg)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(\"Accuracy :\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall   :\", rec)\n",
    "print(\"F1       :\", f1)\n",
    "print(\"ROC AUC  :\", auc)\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MODEL 2 — RANDOM FOREST CLASSIFIER\n",
    "# =========================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", rf)\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "rf_proba = rf_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "rf_prec = precision_score(y_test, rf_pred)\n",
    "rf_rec = recall_score(y_test, rf_pred)\n",
    "rf_f1 = f1_score(y_test, rf_pred)\n",
    "rf_auc = roc_auc_score(y_test, rf_proba)\n",
    "\n",
    "print(\"=== RANDOM FOREST RESULTS ===\")\n",
    "print(\"Accuracy :\", rf_acc)\n",
    "print(\"Precision:\", rf_prec)\n",
    "print(\"Recall   :\", rf_rec)\n",
    "print(\"F1       :\", rf_f1)\n",
    "print(\"ROC AUC  :\", rf_auc)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rf_pred))\n",
    "\n",
    "# =========================\n",
    "# MODEL 3 — GRADIENT BOOSTING CLASSIFIER\n",
    "# =========================\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=300,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", gb)\n",
    "    ]\n",
    ")\n",
    "\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "gb_proba = gb_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "gb_acc = accuracy_score(y_test, gb_pred)\n",
    "gb_prec = precision_score(y_test, gb_pred)\n",
    "gb_rec = recall_score(y_test, gb_pred)\n",
    "gb_f1 = f1_score(y_test, gb_pred)\n",
    "gb_auc = roc_auc_score(y_test, gb_proba)\n",
    "\n",
    "print(\"=== GRADIENT BOOSTING RESULTS ===\")\n",
    "print(\"Accuracy :\", gb_acc)\n",
    "print(\"Precision:\", gb_prec)\n",
    "print(\"Recall   :\", gb_rec)\n",
    "print(\"F1       :\", gb_f1)\n",
    "print(\"ROC AUC  :\", gb_auc)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, gb_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, gb_pred))\n",
    "\n",
    "# =========================\n",
    "# COMPARE ALL THREE MODELS\n",
    "# =========================\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Logistic Regression\", \"Random Forest\", \"Gradient Boosting\"],\n",
    "    \"Accuracy\": [acc, rf_acc, gb_acc],\n",
    "    \"Precision\": [prec, rf_prec, gb_prec],\n",
    "    \"Recall\": [rec, rf_rec, gb_rec],\n",
    "    \"F1 Score\": [f1, rf_f1, gb_f1],\n",
    "    \"ROC AUC\": [auc, rf_auc, gb_auc]\n",
    "})\n",
    "\n",
    "results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fe82ebb-0b56-44ba-ab90-47ce221b2257",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to: /Workspace/Users/sealex@asu.edu/no_show_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# SAVE BEST MODEL (LOGISTIC REGRESSION) TO WORKSPACE FILES\n",
    "# =========================\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "best_model = clf  # logistic regression pipeline\n",
    "\n",
    "# Save in the same Workspace area as your CSV\n",
    "model_path = \"/Workspace/Users/sealex@asu.edu/no_show_model.pkl\"\n",
    "\n",
    "# Create dir if needed\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "\n",
    "joblib.dump(\n",
    "    {\n",
    "        \"pipeline\": best_model,\n",
    "        \"feature_cols\": feature_cols,\n",
    "        \"numeric_features\": numeric_features,\n",
    "        \"binary_int_cols\": binary_int_cols,\n",
    "        \"categorical_features\": categorical_features,\n",
    "    },\n",
    "    model_path\n",
    ")\n",
    "\n",
    "print(f\"Saved best model to: {model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Final_Project",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}